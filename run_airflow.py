# run_airflow.py - Simple Airflow Pipeline Runner
# Student: [Your Name]
# Course: Data Mining & Machine Learning

import os
import subprocess

print("ğŸš€ Customer Churn Pipeline - Using Apache Airflow")
print("=" * 50)
print("This shows our DAG structure and task dependencies")
print()

# Show the DAG structure
print("ğŸ“Š Our Pipeline DAG (Directed Acyclic Graph):")
print("=" * 50)
print("data_ingestion")
print("    â†“")
print("data_storage") 
print("    â†“")
print("data_validation")
print("    â†“")
print("quality_report")
print("    â†“") 
print("data_preparation")
print("    â†“")
print("feature_engineering")
print("    â†“")
print("database_setup")
print("    â†“")
print("feature_store")
print("    â†“")
print("data_versioning")
print()

print("âœ… Key Airflow Features Implemented:")
print("- DAG with proper task dependencies")
print("- Automatic retries on failure")
print("- Task scheduling (daily)")
print("- Failure handling")
print()

# For demonstration, we'll just run our regular pipeline
print("ğŸ”„ Running pipeline tasks in correct order...")
print("(In real Airflow, this would be managed automatically)")
print()

# Run the pipeline in the correct dependency order
result = os.system("python pipeline.py")

if result == 0:
    print()
    print("âœ… Pipeline completed successfully!")
    print("ğŸ“ˆ In real Airflow, you would see this in the web UI")
    print("ğŸ—„ï¸ DAG file: dags/churn_pipeline_dag.py")
else:
    print("âŒ Pipeline failed - Airflow would retry automatically")
