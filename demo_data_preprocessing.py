#!/usr/bin/env python3
"""
Real-time demonstration of the Data Preprocessing System.
Shows live output of data cleaning, preprocessing, and EDA.
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import json

# Add src to path
sys.path.append(str(Path(__file__).parent / 'src'))

from preprocessing.data_preprocessor import create_data_preprocessor
from loguru import logger

def create_sample_dataset():
    """Create a sample dataset for demonstration."""
    print("üìä Creating sample dataset for preprocessing demonstration...")
    
    # Create base data
    np.random.seed(42)
    n_samples = 1000
    
    # Generate realistic churn data
    data = {
        'customer_id': range(1, n_samples + 1),
        'age': np.random.normal(45, 15, n_samples).astype(int),
        'gender': np.random.choice(['Male', 'Female'], n_samples),
        'tenure': np.random.exponential(30, n_samples).astype(int),
        'monthly_charges': np.random.normal(65, 20, n_samples),
        'total_charges': np.random.normal(2000, 1000, n_samples),
        'contract_type': np.random.choice(['Month-to-month', 'One year', 'Two year'], n_samples),
        'payment_method': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], n_samples),
        'internet_service': np.random.choice(['DSL', 'Fiber optic', 'No'], n_samples),
        'online_security': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),
        'online_backup': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),
        'device_protection': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),
        'tech_support': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),
        'streaming_tv': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),
        'streaming_movies': np.random.choice(['Yes', 'No', 'No internet service'], n_samples),
        'paperless_billing': np.random.choice(['Yes', 'No'], n_samples),
        'partner': np.random.choice(['Yes', 'No'], n_samples),
        'dependents': np.random.choice(['Yes', 'No'], n_samples),
        'churn': np.random.choice([0, 1], n_samples, p=[0.7, 0.3])
    }
    
    df = pd.DataFrame(data)
    
    # Introduce some data quality issues for demonstration
    print("  üîç Adding realistic data quality issues...")
    
    # 1. Missing values
    missing_indices = np.random.choice(df.index, size=int(n_samples * 0.05), replace=False)
    df.loc[missing_indices, 'monthly_charges'] = np.nan
    
    missing_indices = np.random.choice(df.index, size=int(n_samples * 0.03), replace=False)
    df.loc[missing_indices, 'contract_type'] = np.nan
    
    # 2. Some outliers
    outlier_indices = np.random.choice(df.index, size=20, replace=False)
    df.loc[outlier_indices, 'monthly_charges'] = np.random.uniform(150, 300, 20)
    
    # 3. Some inconsistent data types
    type_indices = np.random.choice(df.index, size=15, replace=False)
    df.loc[type_indices, 'tenure'] = df.loc[type_indices, 'tenure'].astype(str) + ' months'
    
    print(f"  ‚úÖ Created dataset with {len(df)} rows and {len(df.columns)} columns")
    return df

def demonstrate_preprocessing():
    """Demonstrate the data preprocessing system."""
    print("\n" + "="*80)
    print("üîß DATA PREPROCESSING SYSTEM DEMONSTRATION")
    print("="*80)
    
    # Initialize preprocessor
    print("\nüîß Initializing Data Preprocessor...")
    try:
        preprocessor = create_data_preprocessor()
        print("  ‚úÖ Data preprocessor initialized successfully")
    except Exception as e:
        print(f"  ‚ùå Failed to initialize preprocessor: {e}")
        return
    
    # Create sample dataset
    print("\nüìä Creating Sample Dataset...")
    sample_data = create_sample_dataset()
    
    print(f"\nüìã Dataset Overview:")
    print(f"  ‚Ä¢ Shape: {sample_data.shape}")
    print(f"  ‚Ä¢ Memory usage: {sample_data.memory_usage(deep=True).sum() / 1024:.2f} KB")
    print(f"  ‚Ä¢ Data types: {sample_data.dtypes.value_counts().to_dict()}")
    
    # Perform EDA
    print("\nüîç PERFORMING EXPLORATORY DATA ANALYSIS")
    print("-" * 50)
    
    try:
        eda_results = preprocessor.explore_data(sample_data, save_plots=True)
        
        print(f"\n‚úÖ EDA completed!")
        print(f"  ‚Ä¢ Dataset shape: {eda_results['dataset_info']['shape']}")
        print(f"  ‚Ä¢ Missing data columns: {len(eda_results['missing_data']['columns_with_missing'])}")
        print(f"  ‚Ä¢ Numerical columns: {len(eda_results['numerical_analysis'].get('columns', []))}")
        print(f"  ‚Ä¢ Categorical columns: {len(eda_results['categorical_analysis'].get('columns', []))}")
        
        # Show recommendations
        if eda_results.get('recommendations'):
            print(f"\nüí° EDA Recommendations:")
            for rec in eda_results['recommendations']:
                print(f"  ‚Ä¢ {rec}")
        
    except Exception as e:
        print(f"  ‚ùå EDA failed: {e}")
        return
    
    # Clean data
    print("\nüßπ CLEANING DATA")
    print("-" * 50)
    
    try:
        cleaned_data = preprocessor.clean_data(sample_data)
        
        print(f"\n‚úÖ Data cleaning completed!")
        print(f"  ‚Ä¢ Initial shape: {sample_data.shape}")
        print(f"  ‚Ä¢ Final shape: {cleaned_data.shape}")
        print(f"  ‚Ä¢ Rows removed: {len(sample_data) - len(cleaned_data)}")
        
        # Show cleaning statistics
        cleaning_stats = preprocessor.preprocessing_info['statistics'].get('cleaning', {})
        if cleaning_stats:
            print(f"  ‚Ä¢ Duplicates removed: {cleaning_stats.get('duplicates_removed', 0)}")
            print(f"  ‚Ä¢ Cleaning steps: {len(cleaning_stats.get('steps', []))}")
        
    except Exception as e:
        print(f"  ‚ùå Data cleaning failed: {e}")
        return
    
    # Preprocess data
    print("\n‚öôÔ∏è  PREPROCESSING DATA")
    print("-" * 50)
    
    try:
        preprocessed_data, preprocessing_info = preprocessor.preprocess_data(cleaned_data)
        
        print(f"\n‚úÖ Data preprocessing completed!")
        print(f"  ‚Ä¢ Input shape: {cleaned_data.shape}")
        print(f"  ‚Ä¢ Output shape: {preprocessed_data.shape}")
        print(f"  ‚Ä¢ Features added: {len(preprocessed_data.columns) - len(cleaned_data.columns)}")
        
        # Show preprocessing transformations
        transformations = preprocessing_info.get('transformations', {})
        if transformations.get('encoding'):
            print(f"  ‚Ä¢ Categorical encoding: {len(transformations['encoding'])} columns encoded")
        
        if transformations.get('scaling'):
            print(f"  ‚Ä¢ Numerical scaling: {len(transformations['scaling'].get('columns', []))} columns scaled")
        
    except Exception as e:
        print(f"  ‚ùå Data preprocessing failed: {e}")
        return
    
    # Save preprocessed data
    print("\nüíæ SAVING PREPROCESSED DATA")
    print("-" * 50)
    
    try:
        output_path = preprocessor.save_preprocessed_data(preprocessed_data)
        print(f"  ‚úÖ Preprocessed data saved to: {output_path}")
        
        # Show file info
        file_size = Path(output_path).stat().st_size / 1024  # KB
        print(f"  ‚Ä¢ File size: {file_size:.2f} KB")
        
    except Exception as e:
        print(f"  ‚ùå Failed to save data: {e}")
    
    # Show final dataset info
    print("\nüìä FINAL DATASET INFORMATION")
    print("-" * 50)
    
    print(f"  ‚Ä¢ Final shape: {preprocessed_data.shape}")
    print(f"  ‚Ä¢ Memory usage: {preprocessed_data.memory_usage(deep=True).sum() / 1024:.2f} KB")
    print(f"  ‚Ä¢ Data types: {preprocessed_data.dtypes.value_counts().to_dict()}")
    
    # Show sample of preprocessed data
    print(f"\nüìã Sample of preprocessed data:")
    print(preprocessed_data.head().to_string())
    
    # Show preprocessing steps
    print(f"\nüìù PREPROCESSING STEPS PERFORMED")
    print("-" * 50)
    
    steps = preprocessor.preprocessing_info.get('steps_performed', [])
    for i, step in enumerate(steps, 1):
        print(f"  {i}. {step}")
    
    print("\n‚úÖ DEMONSTRATION COMPLETED!")
    print("="*80)
    print("\nüìù Summary:")
    print(f"  ‚Ä¢ Performed comprehensive EDA with visualizations")
    print(f"  ‚Ä¢ Cleaned dataset with {len(sample_data) - len(cleaned_data)} rows removed")
    print(f"  ‚Ä¢ Preprocessed data with encoding and scaling")
    print(f"  ‚Ä¢ Generated {len(steps)} preprocessing steps")
    print(f"  ‚Ä¢ Saved clean dataset ready for modeling")

def show_preprocessing_configuration():
    """Show the current preprocessing configuration."""
    print("\n‚öôÔ∏è  PREPROCESSING CONFIGURATION")
    print("-" * 50)
    
    config_path = "config/config.yaml"
    if Path(config_path).exists():
        import yaml
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        
        preprocessing_config = config.get('preprocessing', {})
        print("Current preprocessing configuration:")
        print(json.dumps(preprocessing_config, indent=2))
    else:
        print("‚ùå Configuration file not found. Using defaults.")

if __name__ == "__main__":
    print("üéØ Data Preprocessing System Real-time Demonstration")
    print("This script will show you exactly how data preprocessing works.")
    
    # Show configuration
    show_preprocessing_configuration()
    
    # Run demonstration
    demonstrate_preprocessing()
    
    print("\nüéâ All done! Check the plots/eda and data/processed directories to see the results.")
